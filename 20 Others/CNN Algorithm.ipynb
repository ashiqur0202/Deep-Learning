{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755ac0d9-ec80-4c89-b83f-43e93524e329",
   "metadata": {},
   "source": [
    "CNN stands for Convolutional Neural Network, which is a type of neural network used for image recognition and processing tasks. The architecture of a CNN is designed to automatically and adaptively learn spatial hierarchies of features from input data. It is composed of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The convolutional layers apply convolutional filters to the input image to extract important features, while the pooling layers reduce the dimensionality of the feature maps. Finally, the fully connected layers process the output of the previous layers and perform the classification task. CNNs have shown excellent performance in a variety of computer vision tasks, such as object detection, image segmentation, and facial recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91380425-ddbb-4e78-881e-f77720f879c1",
   "metadata": {},
   "source": [
    "__Steps to build a Convolutional Neural Network (CNN):__\n",
    "\n",
    "__Data Preprocessing:__ Load and preprocess the image data. This includes tasks such as normalization, data augmentation, and splitting the data into training, validation, and testing sets.\n",
    "\n",
    "__Building the CNN model:__ The CNN model is built using a sequence of convolutional, pooling, and dense layers. The convolutional layers use filters to extract features from the images, while the pooling layers downsample the feature maps. The dense layers are used for classification.\n",
    "\n",
    "__Compiling the model:__ Specify the loss function, optimizer, and evaluation metric to be used during training.\n",
    "\n",
    "__Training the model:__ Train the CNN model on the training set using the fit() function, specifying the number of epochs and batch size.\n",
    "\n",
    "__Evaluating the model:__ Evaluate the performance of the CNN model on the validation set.\n",
    "\n",
    "__Fine-tuning the model:__ Fine-tune the CNN model by adjusting the hyperparameters and architecture, and repeating the training and evaluation steps until the desired performance is achieved.\n",
    "\n",
    "__Testing the model:__ Test the CNN model on the unseen testing set to measure its accuracy on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5051af-3276-4f66-96fc-9bf51bd0ca27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd345ae-a0f4-4069-a2ff-30522fcdcb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287927ca-03f1-40f2-99c5-70bb1e078bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 1045s 6us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc7f3bf8-58dc-48d5-b556-02ce733070dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f5d428-1e70-4053-8a53-efa906bc3209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff3924d6-4f55-4d73-97e6-b367cb18ff35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953752bc-1480-47bf-9f31-575eade7efa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 93s 58ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 82s 52ms/step - loss: 2.3028 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 94s 60ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 2.3028 - accuracy: 0.0955 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 93s 60ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 79s 51ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 96s 62ms/step - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 2.3028 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 2.3028 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d148a18-e5d9-492e-ba90-49ad75ced547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 5s - loss: 2.3026 - accuracy: 0.1000 - 5s/epoch - 15ms/step\n",
      "Test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
